{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn import grid_search\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2014-02-03T19:24:07Z\n",
    "def parse_time(time):\n",
    "    return datetime.datetime.strptime(time, '%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SECONDS_PER_DAY = 60 * 60 * 24\n",
    "def days_between(start_date, end_date):\n",
    "    return (parse_time(end_date) - parse_time(start_date)).total_seconds() / SECONDS_PER_DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n"
     ]
    }
   ],
   "source": [
    "print days_between('2014-01-03T19:24:07Z', '2014-02-03T19:24:07Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Metadata and Remove Forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_metadata_file = os.path.join('selected_metadata.txt')\n",
    "\n",
    "ID_TO_LINK_MAP_PATH = os.path.join('..', 'data', 'id_to_link_map.json')\n",
    "\n",
    "# Metadata parameters\n",
    "METADATA_INDEX_PATH = os.path.join('..', 'data', 'metadata_index.json')\n",
    "README_ID_INDEX = '0'\n",
    "WATCH_INDEX = '1'\n",
    "STAR_INDEX = '2'\n",
    "FORK_INDEX = '3'\n",
    "COMMIT_INDEX = '4'\n",
    "BRANCH_INDEX = '5'\n",
    "RELEASES_INDEX = '6'\n",
    "CONTRIB_INDEX = '7'\n",
    "LATEST_AUTHOR_INDEX = '8'\n",
    "DESCRIPTION_INDEX = '9'\n",
    "LATEST_README_INDEX = '10'\n",
    "FIRST_README_INDEX = '11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata.\n",
      "Loading id-to-link map.\n",
      "Calculating document scores.\n",
      "Total ids: 109284\n",
      "\t[('925608', 56.280203692020059), ('1752', 49.333310948199632), ('70403', 46.999755966372348), ('72644', 43.151584591348701), ('1031723', 38.364214516268987)]\n",
      "Removing forks\n",
      "Number of ids after cleaning: 106279\n",
      "Dumping cleaned ids...\n"
     ]
    }
   ],
   "source": [
    "print 'Loading metadata.'\n",
    "metadata_index = json.load(open(METADATA_INDEX_PATH))\n",
    "\n",
    "\n",
    "print 'Loading id-to-link map.'\n",
    "id_to_link_map = json.load(open(ID_TO_LINK_MAP_PATH))\n",
    "\n",
    "all_ids = []\n",
    "all_scores = []\n",
    "\n",
    "print 'Calculating document scores.'\n",
    "header = True\n",
    "for line in open(selected_metadata_file):\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    parts = line.strip().split()\n",
    "    doc_id = parts[0]\n",
    "\n",
    "    doc_score = 1\n",
    "\n",
    "    if doc_id in metadata_index:\n",
    "        doc_metadata = metadata_index[doc_id]\n",
    "        if WATCH_INDEX in doc_metadata:\n",
    "            doc_score *= np.log10(doc_metadata[WATCH_INDEX])\n",
    "        if STAR_INDEX in doc_metadata:\n",
    "            doc_score *= np.log10(doc_metadata[STAR_INDEX])\n",
    "        if CONTRIB_INDEX in doc_metadata:\n",
    "            doc_score *= np.log10(doc_metadata[CONTRIB_INDEX])\n",
    "    \n",
    "    all_ids.append( (doc_id, doc_score) )\n",
    "\n",
    "all_ids.sort(reverse = True, key = lambda t: t[1])\n",
    "print 'Total ids:', len(all_ids)\n",
    "print '\\t', all_ids[:5]\n",
    "\n",
    "\n",
    "# Remove forked projects from results.\n",
    "# Our assumption is that one repo is a fork of another if:\n",
    "# 1. They have the same repo description (raw) and repo name (derived from url).\n",
    "\n",
    "name_to_description = collections.defaultdict(set)\n",
    "\n",
    "print 'Removing forks'\n",
    "clean_ids = []\n",
    "for t in all_ids:\n",
    "\n",
    "    doc_id = t[0]\n",
    "    if doc_id not in id_to_link_map:\n",
    "        continue\n",
    "        \n",
    "    doc_url = id_to_link_map[doc_id]\n",
    "    # Name is last part of the url.\n",
    "    doc_name = doc_url.split('/')[-1].lower()\n",
    "\n",
    "    add_to_clean = False\n",
    "    # 1\n",
    "    if not add_to_clean and doc_id in metadata_index:\n",
    "        doc_metadata = metadata_index[doc_id]\n",
    "        if DESCRIPTION_INDEX in doc_metadata:\n",
    "            doc_description = doc_metadata[DESCRIPTION_INDEX]\n",
    "            # Simple description normalization.\n",
    "            if len(doc_description) > 0 and doc_description[-1] == '.':\n",
    "                doc_description = doc_description[:-1]\n",
    "            #\n",
    "            if doc_description not in name_to_description[doc_name]:\n",
    "                name_to_description[doc_name].add(doc_description)\n",
    "                add_to_clean = True\n",
    "\n",
    "    if add_to_clean:\n",
    "         clean_ids.append(doc_id)\n",
    "\n",
    "# Number of ids after cleaning\n",
    "print 'Number of ids after cleaning:', len(clean_ids)            \n",
    "            \n",
    "print 'Dumping cleaned ids...'\n",
    "json.dump(clean_ids, open(os.path.join('clean_ids.json'), 'w+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Precomputed Clean IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_ids = json.load(open(os.path.join('clean_ids.json')))\n",
    "clean_ids_set = set(clean_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Lifespan Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108966\n"
     ]
    }
   ],
   "source": [
    "header = True\n",
    "for line in open(selected_metadata):\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    parts = line.strip().split()\n",
    "    doc_id = parts[0]\n",
    "    between = days_between(parts[2], parts[3])\n",
    "    meta_days_between.append(between)\n",
    "    \n",
    "    for class_label, upper_bound in enumerate(class_upper_bounds):\n",
    "        if between <= upper_bound:\n",
    "            class_buckets[class_label].append( (doc_id, parts[2], parts[3]) )\n",
    "            break\n",
    "    \n",
    "meta_days_between = [m for m in meta_days_between if m >= 0]\n",
    "print len(meta_days_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.06830000e+04,   1.03880000e+04,   6.01400000e+03,\n",
       "          3.86200000e+03,   2.31600000e+03,   1.56100000e+03,\n",
       "          1.10500000e+03,   8.14000000e+02,   6.02000000e+02,\n",
       "          3.66000000e+02,   3.16000000e+02,   1.78000000e+02,\n",
       "          1.25000000e+02,   9.70000000e+01,   9.30000000e+01,\n",
       "          7.80000000e+01,   5.70000000e+01,   6.20000000e+01,\n",
       "          6.30000000e+01,   4.70000000e+01,   2.20000000e+01,\n",
       "          1.80000000e+01,   1.30000000e+01,   7.00000000e+00,\n",
       "          1.20000000e+01,   5.00000000e+00,   9.00000000e+00,\n",
       "          9.00000000e+00,   3.00000000e+00,   9.00000000e+00,\n",
       "          6.00000000e+00,   4.00000000e+00,   2.00000000e+00,\n",
       "          4.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
       "          2.00000000e+00,   4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   2.00000000e+00]),\n",
       " array([    0.        ,   116.43376319,   232.86752639,   349.30128958,\n",
       "          465.73505278,   582.16881597,   698.60257917,   815.03634236,\n",
       "          931.47010556,  1047.90386875,  1164.33763194,  1280.77139514,\n",
       "         1397.20515833,  1513.63892153,  1630.07268472,  1746.50644792,\n",
       "         1862.94021111,  1979.37397431,  2095.8077375 ,  2212.24150069,\n",
       "         2328.67526389,  2445.10902708,  2561.54279028,  2677.97655347,\n",
       "         2794.41031667,  2910.84407986,  3027.27784306,  3143.71160625,\n",
       "         3260.14536944,  3376.57913264,  3493.01289583,  3609.44665903,\n",
       "         3725.88042222,  3842.31418542,  3958.74794861,  4075.18171181,\n",
       "         4191.615475  ,  4308.04923819,  4424.48300139,  4540.91676458,\n",
       "         4657.35052778,  4773.78429097,  4890.21805417,  5006.65181736,\n",
       "         5123.08558056,  5239.51934375,  5355.95310694,  5472.38687014,\n",
       "         5588.82063333,  5705.25439653,  5821.68815972]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGoBJREFUeJzt3X+QVed93/H3x8JgZFOYlVtAgCSUrFqjOrZMa5zYjleR\n",
       "QrHHkTStRsKdaJhk6z9CUqnt1DX4j4r+0cRkpsXydKROU2whxqaiVqwfYw0GuabTmQ5aO0YxFiZA\n",
       "Gwq7mMUDKSK/Wog+/eM8W45WK55d9q72snxeMzv3ud/7nLPPl2Huh3POvRzZJiIi4nLeMd0LiIiI\n",
       "7pewiIiIqoRFRERUJSwiIqIqYREREVUJi4iIqKqGhaRHJB2Q9CNJj5Raj6Q9kg5L2i1pQWv+RklH\n",
       "JB2StLpVX1n2c0TSY636HElPl/o+STd3usmIiJicy4aFpL8N/CPg7wIfAD4t6WeADcAe27cB3ynP\n",
       "kbQCeBBYAawBHpeksrsngH7bvUCvpDWl3g+cKfUtwOYO9hcRER1QO7L4W8DLtv/S9l8B/xX4B8A9\n",
       "wLYyZxtwXxnfC+ywfcH2MeAosErSYmCe7YEy76nWNu19PQPcNbmWIiKi02ph8SPg4+W00/XAp4Cl\n",
       "wELbw2XOMLCwjG8EBlvbDwJLxqgPlTrl8QSA7YvAOUk9V9ZORERMhVmXe9H2IUmbgd3AnwGvAH81\n",
       "ao4l5f8MiYiYwS4bFgC2vwJ8BUDSv6Y5QhiWtMj2qXKK6XSZPgQsa22+tMwfKuPR9ZFtbgJOSpoF\n",
       "zLd9dvQ6EkgREVfGtuqzLq8aFpL+hu3Tkm4C/j7wEWA5sI7mYvQ64Nky/Xng65L+Lc3ppV5goBx9\n",
       "vCZpFTAAPAR8ubXNOmAfcD/NBfMxdaLhbiVpk+1N072OqTCTe4P0d7W7BvrryD+0q2EBfEPSDcAF\n",
       "YL3tc5K+COyU1A8cAx4AsH1Q0k7gIHCxzB9Z6HrgSWAu8KLtXaW+Fdgu6QhwBljbicYiIqJzxnMa\n",
       "6hfHqJ0F7n6L+b8N/PYY9T8A3j9G/f9QwiYiIrpTvsHdPfZO9wKm0N7pXsAU2zvdC5hie6d7AVNs\n",
       "73Qv4Gqgq+XmR5I8k69ZRERMhU69d+bIIiIiqhIWERFRlbCIiIiqhEVERFQlLCIioiphERERVQmL\n",
       "iIioSlhERERVwiIiIqoSFhERUZWwiIiIqoRFRERUJSwiIqIqYREREVXVsJC0UdKrkg5I+rqkOZJ6\n",
       "JO2RdFjSbkkLRs0/IumQpNWt+sqyjyOSHmvV50h6utT3Sbq5821GRMRkXDYsJN0CfBb4kO33A9fR\n",
       "3PZ0A7DH9m0098zeUOavAB4EVgBrgMcljfw/6k8A/bZ7gV5Ja0q9HzhT6lto7usdERFdpHZk8RrN\n",
       "vbevlzQLuB44CdwDbCtztgH3lfG9wA7bF2wfA44CqyQtBubZHijznmpt097XM8Bdb7UY6YbDb/55\n",
       "z0vj7DUiIq7QZe/BbfuspH8DHAf+Avi27T2SFtoeLtOGgYVlfCOwr7WLQWAJTeAMtupDpU55PFF+\n",
       "30VJ5yT1lPt8j7Kr943PTwH/8IbLtxgREZN12bCQ9DPAPwFuAc4B/1nSr7bn2Lakt+nerN9qjfuA\n",
       "D7w9vzYi4iohqY/mDbKjLhsWwN8B/rvtM2URvw/8PHBK0iLbp8opptNl/hCwrLX9UpojiqEyHl0f\n",
       "2eYm4GQ51TV/7KMKgE2jnh+vLD8i4tpiey+wd+S5pEc7sd/aNYtDwEckzS0Xqu8GDgIvAOvKnHXA\n",
       "s2X8PLBW0mxJy4FeYMD2KeA1SavKfh4CnmttM7Kv+2kumEdERBepXbP4Q0lPAd8HXgd+APwHYB6w\n",
       "U1I/cAx4oMw/KGknTaBcBNbbHjlFtR54EpgLvGh7V6lvBbZLOgKcofm0VUREdBFdei/vbs11kdFr\n",
       "PQ7cftY+n4vcERFjkGTbqs+8vHyDOyIiqhIWERFRlbCIiIiqhEVERFQlLCIioiphERERVQmLiIio\n",
       "SlhERERVwiIiIqoSFhERUZWwiIiIqoRFRERUJSwiIqIqYREREVUJi4iIqEpYREREVTUsJP1NSftb\n",
       "P+ckPSypR9IeSYcl7Za0oLXNRklHJB2StLpVXynpQHntsVZ9jqSnS32fpJs732pERFypaljY/iPb\n",
       "d9i+A1gJ/DnwTWADsMf2bTT3zd4AIGkF8CCwAlgDPF7uuw3wBNBvuxfolbSm1PuBM6W+BdjcqQYj\n",
       "ImLyJnoa6m7gqO0TwD3AtlLfBtxXxvcCO2xfsH0MOAqskrQYmGd7oMx7qrVNe1/PAHdNtJGIiJg6\n",
       "Ew2LtcCOMl5oe7iMh4GFZXwjMNjaZhBYMkZ9qNQpjycAbF8EzknqmeDaIiJiiswa70RJs4FfAT4/\n",
       "+jXbluROLmxsm1rjPuDWqf+VERFXEUl9NG+QHTXusAA+CfyB7Z+W58OSFtk+VU4xnS71IWBZa7ul\n",
       "NEcUQ2U8uj6yzU3ASUmzgPm2z755CZtGPT8+geVHRMx8tvcCe0eeS3q0E/udyGmoz3DpFBTA88C6\n",
       "Ml4HPNuqr5U0W9JyoBcYsH0KeE3SqnLB+yHguTH2dT/NBfOIiOgSsutnjyS9G/hfwHLb50utB9hJ\n",
       "c0RwDHjA9v8ur30B+HXgIvCI7W+X+krgSWAu8KLth0t9DrAduAM4A6wtF8fbazCMXutx4Paz9vkb\n",
       "Jtp4RMS1QJJtqz6zsp/xhEU3SFhERExcp8Ii3+COiIiqhEVERFQlLCIioiphERERVQmLiIioSlhE\n",
       "RERVwiIiIqoSFhERUZWwiIiIqoRFRERUJSwiIqIqYREREVUJi4iIqEpYREREVcIiIiKqEhYREVE1\n",
       "rrCQtEDSNyT9WNLBcmvUHkl7JB2WtFvSgtb8jZKOSDokaXWrvlLSgfLaY636HElPl/o+STd3ts2I\n",
       "iJiM8R5ZPEZzG9T3AT8HHAI2AHts30Zzz+wNAJJWAA8CK4A1wOPlntsATwD9tnuBXklrSr0fOFPq\n",
       "W4DNk+4sIiI6phoWkuYDH7f9FQDbF22fA+4BtpVp24D7yvheYIftC+U+2keBVZIWA/NsD5R5T7W2\n",
       "ae/rGeCuSXUVEREdNZ4ji+XATyV9VdIPJP2epHcDC20PlznDwMIyvhEYbG0/CCwZoz5U6pTHE9CE\n",
       "EXBOUs+VNBQREZ03a5xzPgT8lu3vSfoS5ZTTCNuW5KlY4Bttao37gFun/ldGRFxFJPXRvEF21HjC\n",
       "YhAYtP298vwbwEbglKRFtk+VU0yny+tDwLLW9kvLPobKeHR9ZJubgJOSZgHzbZ9981I2jXp+fBzL\n",
       "j4i4dtjeC+wdeS7p0U7st3oayvYp4ISk20rpbuBV4AVgXamtA54t4+eBtZJmS1oO9AIDZT+vlU9S\n",
       "CXgIeK61zci+7qe5YB4REV1iPEcWAP8Y+Jqk2cD/AH4NuA7YKakfOAY8AGD7oKSdwEHgIrDe9sgp\n",
       "qvXAk8Bcmk9X7Sr1rcB2SUeAM8DaSfYVEREdpEvv492tuSYyeq3HgdvP2udvmI41RUR0O0m2rfrM\n",
       "y8s3uCMioiphERERVQmLiIioSlhERERVwiIiIqoSFhERUZWwiIiIqoRFRERUJSwiIqIqYREREVUJ\n",
       "i4iIqEpYREREVcIiIiKqEhYREVGVsIiIiKpxhYWkY5J+KGm/pIFS65G0R9JhSbslLWjN3yjpiKRD\n",
       "kla36islHSivPdaqz5H0dKnvk3RzJ5uMiIjJGe+RhYE+23fY/nCpbQD22L6N5jaoGwAkrQAeBFYA\n",
       "a4DHy21UAZ4A+m33Ar2S1pR6P3Cm1LcAmyfZV0REdNBETkONvtPSPcC2Mt4G3FfG9wI7bF+wfQw4\n",
       "CqyStBiYZ3ugzHuqtU17X88Ad01gXRERMcUmcmTxkqTvS/psqS20PVzGw8DCMr4RGGxtOwgsGaM+\n",
       "VOqUxxMAti8C5yT1TKSRiIiYOrPGOe+jtn8i6a8DeyQdar9o2809siMiYiYaV1jY/kl5/KmkbwIf\n",
       "BoYlLbJ9qpxiOl2mDwHLWpsvpTmiGCrj0fWRbW4CTkqaBcy3ffbNK9nUGvcBt45n+RER1wxJfTRv\n",
       "kJ3dr335AwJJ1wPX2T4v6d3AbuBfAXfTXJTeLGkDsMD2hnKB++s0gbIEeAn42XL08TLwMDAAfAv4\n",
       "su1dktYD77f9G5LWAvfZXjtqHW7OhrUdB24/a5+/YXJ/DBERM5Mk2x59zXnCxnNksRD4ZvlA0yzg\n",
       "a7Z3S/o+sFNSP3AMeADA9kFJO4GDwEVgvS8l0nrgSWAu8KLtXaW+Fdgu6QhwBnhDUERExPSqHll0\n",
       "ixxZRERMXKeOLPIN7oiIqEpYREREVcIiIiKqEhYREVGVsIiIiKqERUREVCUsIiKiKmERERFVCYuI\n",
       "iKhKWERERFXCIiIiqhIWERFRlbCIiIiqhEVERFQlLCIioiphERERVeMKC0nXSdov6YXyvEfSHkmH\n",
       "Je2WtKA1d6OkI5IOSVrdqq+UdKC89lirPkfS06W+T9LNnWwwIiImb7xHFo/Q3CZ15FZ1G4A9tm8D\n",
       "vlOeU+6//SCwAlgDPK5yP1bgCaDfdi/QK2lNqffT3Mu7F9gCbJ5cSxER0WnVsJC0FPgU8B+BkTf+\n",
       "e4BtZbwNuK+M7wV22L5g+xhwFFglaTEwz/ZAmfdUa5v2vp4B7rribiIiYkqM58hiC/A54PVWbaHt\n",
       "4TIeBhaW8Y3AYGveILBkjPpQqVMeTwDYvgick9QzgR4iImKKXTYsJH0aOG17P5eOKt7Atrl0eioi\n",
       "ImagWZXXfwG4R9KngHcBf03SdmBY0iLbp8opptNl/hCwrLX9UpojiqEyHl0f2eYm4KSkWcB822fH\n",
       "Xs6m1rgPuLWy/IiIa4ukPpo3yM7utzkwGNcCPgH8c9u/Iul3aS5Kb5a0AVhge0O5wP114MM0p5de\n",
       "An7WtiW9DDwMDADfAr5se5ek9cD7bf+GpLXAfbbXjvH7/eYDmOPA7Wft8zdcUfcRETOcJNse88zQ\n",
       "RNSOLEYbebf+IrBTUj9wDHgAwPZBSTtpPjl1EVjvS2m0HngSmAu8aHtXqW8Ftks6ApwB3hQUEREx\n",
       "vcZ9ZDHdcmQRETFxnTqyyDe4IyKiKmERERFVCYuIiKhKWERERFXCIiIiqhIWERFRlbCIiIiqhEVE\n",
       "RFQlLCIioiphERERVQmLiIioSlhERERVwiIiIqoSFhERUZWwiIiIqoRFRERUXTYsJL1L0suSXpF0\n",
       "UNLvlHqPpD2SDkvaLWlBa5uNko5IOiRpdau+UtKB8tpjrfocSU+X+j5JN09FoxERceUuGxa2/xK4\n",
       "0/YHgZ8D7pT0MWADsMf2bcB3ynPKPbgfBFYAa4DHJY3coekJoN92L9AraU2p99Pcz7sX2AJs7mSD\n",
       "ERExedXTULb/vAxnA9cBfwLcA2wr9W3AfWV8L7DD9gXbx4CjwCpJi4F5tgfKvKda27T39Qxw1xV3\n",
       "ExERU6IaFpLeIekVYBj4ru1XgYW2h8uUYWBhGd8IDLY2HwSWjFEfKnXK4wkA2xeBc5J6rqydiIiY\n",
       "CrNqE2y/DnxQ0nzg25LuHPW6JXmqFvhGm1rjPuDWt+fXRkRcJST10bxBdlQ1LEbYPifpW8BKYFjS\n",
       "Itunyimm02XaELCstdlSmiOKoTIeXR/Z5ibgpKRZwHzbZ8dexaZRz4+Pd/kREdcE23uBvSPPJT3a\n",
       "if3WPg313pFPOkmaC/wysB94HlhXpq0Dni3j54G1kmZLWg70AgO2TwGvSVpVLng/BDzX2mZkX/fT\n",
       "XDCPiIguUjuyWAxsk/QOmmDZbvs7kvYDOyX1A8eABwBsH5S0EzgIXATW2x45RbUeeBKYC7xoe1ep\n",
       "bwW2SzoCnAHWdqq5iIjoDF16L+9uzXWR0Ws9Dtx+1j5/w3SsKSKi20mybdVnXl6+wR0REVUJi4iI\n",
       "qEpYREREVcIiIiKqEhYREVGVsIiIiKqERUREVCUsIiKiKmERERFVCYuIiKhKWERERFXCIiIiqhIW\n",
       "ERFRlbCIiIiqhEVERFQlLCIioqoaFpKWSfqupFcl/UjSw6XeI2mPpMOSdo/cfrW8tlHSEUmHJK1u\n",
       "1VdKOlBee6xVnyPp6VLfJ+nmTjcaERFXbjxHFheAf2r7duAjwG9Keh+wAdhj+zaa+2ZvAJC0AngQ\n",
       "WAGsAR4v990GeALot90L9EpaU+r9wJlS3wJs7kh3ERHREdWwsH3K9itl/KfAj4ElwD3AtjJtG3Bf\n",
       "Gd8L7LB9wfYx4CiwStJiYJ7tgTLvqdY27X09A9w1maYiIqKzJnTNQtItwB3Ay8BC28PlpWFgYRnf\n",
       "CAy2NhukCZfR9aFSpzyeALB9ETgnqWcia4uIiKkza7wTJb2H5l/9j9g+f+nMEti2JE/B+kbZ1Br3\n",
       "AbdO/a+MiLiKSOqjeYPsqHGFhaR30gTFdtvPlvKwpEW2T5VTTKdLfQhY1tp8Kc0RxVAZj66PbHMT\n",
       "cFLSLGC+7bNvXsmmUc+Pj2f5ERHXDNt7gb0jzyU92on9jufTUAK2Agdtf6n10vPAujJeBzzbqq+V\n",
       "NFvScqAXGLB9CnhN0qqyz4eA58bY1/00F8wjIqJLjOfI4qPArwI/lLS/1DYCXwR2SuoHjgEPANg+\n",
       "KGkncBC4CKy3PXKKaj3wJDAXeNH2rlLfCmyXdAQ4A6ydZF8REdFBuvQ+3t2aayKj13ocuP2sff6G\n",
       "6VhTRES3k2Tbqs+8vHyDOyIiqhIWERFRlbCIiIiqhEVERFQlLCIioiphERERVQmLiIioSlhERERV\n",
       "wiIiIqoSFhERUZWwiIiIqoRFRERUJSwiIqIqYREREVUJi4iIqEpYRERE1Xhuq/oVScOSDrRqPZL2\n",
       "SDosabekBa3XNko6IumQpNWt+kpJB8prj7XqcyQ9Xer7JN3cyQYjImLyxnNk8VVgzajaBmCP7dto\n",
       "7pe9AUDSCuBBYEXZ5vFyv22AJ4B+271Ar6SRffYDZ0p9C7B5Ev1ERMQUqIaF7f8G/Mmo8j3AtjLe\n",
       "BtxXxvcCO2xfsH0MOAqskrQYmGd7oMx7qrVNe1/PAHddQR8RETGFrvSaxULbw2U8DCws4xuBwda8\n",
       "QWDJGPWhUqc8ngCwfRE4J6ln/Ev50x5JfqufCfYVERFjmDXZHdh+G9+UN7XGfcCtI6t4i/mTvkd5\n",
       "RMRVRVIfzRtkR11pWAxLWmT7VDnFdLrUh4BlrXlLaY4ohsp4dH1km5uAk5JmAfNtnx37124a9fz4\n",
       "FS4/ImJmsr0X2DvyXNKjndjvlZ6Geh5YV8brgGdb9bWSZktaDvQCA7ZPAa9JWlUueD8EPDfGvu6n\n",
       "uWAeERFdpHpkIWkH8AngvZJOAP8S+CKwU1I/cAx4AMD2QUk7gYPARWC97ZFzROuBJ4G5wIu2d5X6\n",
       "VmC7pCPAGWBtZ1qLiIhO0aX38u7WXBcZvdbjwM1c7pqF7Vy4iIhrliR34n0w3+COiIiqhEVERFQl\n",
       "LCIioiphERERVQmLiIiomvQ3uLvdW327PJ+SiogYvxkfFmN/rDY5ERExETkNFRERVQmLiIioSlhE\n",
       "RETVNXDNYmyX+2/Vc/E7IuKNrtmwyD0wIiLGL6ehIiKiKmERERFV1/BpqLeWL/JFRLxR1xxZSFoj\n",
       "6ZCkI5I+P72r8Rg/ERHXrq4IC0nXAf8OWAOsAD4j6X3Tu6o3k+S3+unAvvs6sMSuNJN7g/R3tZvp\n",
       "/XVKV4QF8GHgqO1jti8A/wm4d5rXNIaxjjianOhAiPR1erVdpG+6FzDF+qZ7AVOsb7oXMMX6pnsB\n",
       "V4NuuWaxBDjRej4IrJqmtVyhsf8PqokEhqRHIddGIqL7dEtYjPMN9ZfOvfH5X7wDmNfx1XTU5b7P\n",
       "0X5tU/mZWMBMRkIpIsZL9vRfvJX0EWCT7TXl+UbgddubW3Omf6EREVehTvzDsFvCYhbwR8BdwElg\n",
       "APiM7R9P68IiIgLoktNQti9K+i3g28B1wNYERURE9+iKI4uIiOhu3fLR2bfUXV/WGz9JX5E0LOlA\n",
       "q9YjaY+kw5J2S1rQem1j6fGQpNWt+kpJB8prj73dfYxF0jJJ35X0qqQfSXq41GdKf++S9LKkVyQd\n",
       "lPQ7pT4j+hsh6TpJ+yW9UJ7PmP4kHZP0w9LfQKnNpP4WSPqGpB+Xv6Orprw/2137Q3NK6ihwC/BO\n",
       "4BXgfdO9rnGu/ePAHcCBVu13gX9Rxp8HvljGK0pv7yy9HuXSUd8A8OEyfhFY0wW9LQI+WMbvobne\n",
       "9L6Z0l9Zy/XlcRawD/jYTOqvrOefAV8Dnp9Jfz/LWv4Y6BlVm0n9bQN+vfV3dP5U9zftTVf+QH4e\n",
       "2NV6vgHYMN3rmsD6b+GNYXEIWFjGi4BDZbwR+Hxr3i7gI8Bi4Met+lrg3093X2P0+Sxw90zsD7ge\n",
       "+B5w+0zqD1gKvATcCbww0/5+0oTFDaNqM6I/mmD4n2PUp7S/bj8NNdaX9ZZM01o6YaHt4TIeBhaW\n",
       "8Y00vY0Y6XN0fYgu61/SLTRHUC8zg/qT9A5Jr9D08V3brzKD+gO2AJ8DXm/VZlJ/Bl6S9H1Jny21\n",
       "mdLfcuCnkr4q6QeSfk/Su5ni/ro9LGbs1Xc3UX5V9yfpPcAzwCO2z7dfu9r7s/267Q/S/Av8FyXd\n",
       "Oer1q7Y/SZ8GTtvez1vc7etq7q/4qO07gE8Cvynp4+0Xr/L+ZgEfAh63/SHgz2jOuvx/U9Fft4fF\n",
       "ELCs9XwZb0zCq82wpEUAkhYDp0t9dJ9LafocKuN2fehtWGeVpHfSBMV228+W8ozpb4Ttc8C3gJXM\n",
       "nP5+AbhH0h8DO4BfkrSdmdMftn9SHn8KfJPm/5+bKf0NAoO2v1eef4MmPE5NZX/dHhbfB3ol3SJp\n",
       "NvAg8Pw0r2kyngfWlfE6mnP9I/W1kmZLWg70AgO2TwGvlU86CHiotc20KWvZChy0/aXWSzOlv/eO\n",
       "fJJE0lzgl4H9zJD+bH/B9jLby2nOU/8X2w8xQ/qTdL2keWX8bmA1cIAZ0l9Z1wlJt5XS3cCrwAtM\n",
       "ZX/TfbFmHBdzPknzaZujwMbpXs8E1r2D5tvo/5fmusuvAT00FxUPA7uBBa35Xyg9HgL+Xqu+kuYv\n",
       "+lHgy9PdV1nTx2jOdb9C8ya6n+a/l58p/b0f+EHp74fA50p9RvQ3qtdPcOnTUDOiP5pz+q+Unx+N\n",
       "vG/MlP7Kuj5A88GLPwR+n+ai95T2ly/lRUREVbefhoqIiC6QsIiIiKqERUREVCUsIiKiKmERERFV\n",
       "CYuIiKhKWERERFXCIiIiqv4fKrQroM2lfWAAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3383f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(meta_days_between, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 66055\n",
      "1 6774\n",
      "2 8615\n",
      "3 16607\n",
      "4 11233\n",
      "Total: 109284\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(NUM_CLASSES):\n",
    "    total += len(class_buckets[i])\n",
    "    print i, len(class_buckets[i])\n",
    "print 'Total:', total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10000\n",
      "Progress: 20000\n",
      "Progress: 30000\n",
      "Progress: 40000\n",
      "Progress: 50000\n",
      "Progress: 60000\n",
      "Progress: 70000\n",
      "Progress: 80000\n",
      "Progress: 90000\n",
      "Progress: 100000\n",
      "Number of valid READMEs 95000\n"
     ]
    }
   ],
   "source": [
    "readmes = []\n",
    "classes = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for c in range(NUM_CLASSES):\n",
    "    for entry in class_buckets[c]:\n",
    "        if parse_time(entry[1]).year != 2015:\n",
    "            readme_path = os.path.join('data', 'clean', str(int(entry[0])/1000000) , entry[0] + '.md')\n",
    "            try: # Some READMEs may have had no content after being cleaned.\n",
    "                readme = ' '.join(open(readme_path).readlines())\n",
    "                readmes.append( readme )\n",
    "                classes.append(c)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % 10000 == 0:\n",
    "            print 'Progress:', counter\n",
    "\n",
    "print 'Number of valid READMEs', len(readmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))  # for  unigrams only use ngram_range=(1, 1)\n",
    "readme_term_matrix = vectorizer.fit_transform(readmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_train, matrix_test, classes_train, classes_test = \\\n",
    "    train_test_split(readme_term_matrix, classes, test_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Using Only Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_grid = dict(\n",
    "    estimator__C=[1e-2, 1e-1, 1, 1e1, 1e2],  # you can also build this using np.logspace\n",
    "    estimator__class_weight=['auto', None])\n",
    "\n",
    "clf = grid_search.GridSearchCV(OneVsRestClassifier(LinearSVC()), parameter_grid, cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:  2.6min\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: DeprecationWarning: Function multilabel_ is deprecated; Attribute multilabel_ is deprecated and will be removed in 0.17. Use 'y_type_.startswith('multilabel')' instead\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 98.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "       estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "          n_jobs=1),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'estimator__class_weight': ['auto', None], 'estimator__C': [0.01, 0.1, 1, 10.0, 100.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(matrix_train, classes_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_list = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76000 76000\n"
     ]
    }
   ],
   "source": [
    "print len(predictions), len(classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 35350\n",
      "Error Percentage 46.5131578947 %\n",
      "=====\n",
      "0 6018 13.8227254979\n",
      "1 3961 98.166047088\n",
      "2 5941 96.0084033613\n",
      "3 11568 86.990524891\n",
      "4 7862 87.9221650637\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "\n",
    "class_errors = collections.defaultdict(int)\n",
    "\n",
    "for actual, pred in zip(classes_test, predictions_list):\n",
    "    if actual != pred:\n",
    "        errors += 1\n",
    "        class_errors[actual] += 1\n",
    "        \n",
    "print 'Number of errors:', errors\n",
    "print 'Error Percentage', errors * 100.0 / len(predictions_list) , '%'\n",
    "\n",
    "print '====='\n",
    "for c in range(NUM_CLASSES):\n",
    "    print c, class_errors[c], class_errors[c] * 100.0 / list(classes_test).count(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Using Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict Latest Commit Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_buckets = collections.defaultdict(list)\n",
    "\n",
    "header = True\n",
    "for line in open(selected_metadata_file):\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    parts = line.strip().split()\n",
    "    doc_id = parts[0]\n",
    "    \n",
    "    if doc_id not in clean_ids_set:\n",
    "        continue\n",
    "    \n",
    "    latest_commit = parse_time(parts[3])\n",
    "\n",
    "    class_buckets[latest_commit.year].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\tAmount\n",
      "2008 \t597\n",
      "2009 \t1777\n",
      "2010 \t841\n",
      "2011 \t4054\n",
      "2012 \t8991\n",
      "2013 \t17818\n",
      "2014 \t43932\n",
      "2015 \t28231\n",
      "\n",
      "\n",
      "\n",
      "['6', '10', '28', '31', '36', '39', '44', '45', '80', '93']\n"
     ]
    }
   ],
   "source": [
    "print 'Year\\tAmount'\n",
    "for k in class_buckets:\n",
    "    if k > 2007:\n",
    "        print k, '\\t', len(class_buckets[k])\n",
    "\n",
    "print '\\n\\n'\n",
    "print class_buckets[2008][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10000\n",
      "Progress: 20000\n",
      "Progress: 30000\n",
      "Progress: 40000\n",
      "Progress: 50000\n",
      "Progress: 60000\n",
      "Progress: 70000\n",
      "Progress: 80000\n",
      "Progress: 90000\n",
      "Progress: 100000\n",
      "Number of valid READMEs 106241\n"
     ]
    }
   ],
   "source": [
    "readmes = []\n",
    "classes = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for k in class_buckets:\n",
    "    if k > 2007:\n",
    "        for entry in class_buckets[k]:\n",
    "            readme_path = os.path.join('..', 'data', 'clean', str(int(entry)/1000000) , entry + '.md')\n",
    "            try: # Some READMEs may have had no content after being cleaned.\n",
    "                readme = ' '.join(open(readme_path).readlines())\n",
    "                readmes.append( readme )\n",
    "                #if os.path.isfile(readme_path):\n",
    "                #    classes.append(k)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            counter += 1\n",
    "            if counter % 10000 == 0:\n",
    "                print 'Progress:', counter\n",
    "\n",
    "print 'Number of valid READMEs', len(readmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), max_df=0.6, min_df=2)  # for  unigrams only use ngram_range=(1, 1)\n",
    "readme_term_matrix = vectorizer.fit_transform(readmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106241, 1932418)\n"
     ]
    }
   ],
   "source": [
    "print readme_term_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save readme_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106241, 8550277)\n"
     ]
    }
   ],
   "source": [
    "print readme_term_matrix.shape\n",
    "pickle.dump(readme_term_matrix, open('readme_term_matrix.p', 'w+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load readme_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106241, 8550277)\n"
     ]
    }
   ],
   "source": [
    "# (106241, 8550277)\n",
    "readme_term_matrix = pickle.load(open('readme_term_matrix.p'))\n",
    "print readme_term_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_train, matrix_test, classes_train, classes_test = \\\n",
    "    train_test_split(readme_term_matrix, classes, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(clf, clf_name, matrix_train, classes_train, matrix_test, classes_test):\n",
    "    clf.fit(matrix_train, classes_train)\n",
    "\n",
    "    multi_nb_predictions = clf.predict(matrix_test)\n",
    "\n",
    "    errors = 0\n",
    "\n",
    "    class_errors = collections.defaultdict(int)\n",
    "\n",
    "    for actual, pred in zip(classes_test, multi_nb_predictions):\n",
    "        if actual != pred:\n",
    "            errors += 1\n",
    "            class_errors[actual] += 1\n",
    "\n",
    "    print 'Classifier:', clf_name\n",
    "    print 'Number of training examples:', matrix_train.shape[0]\n",
    "    print 'Number of test examples:', matrix_test.shape[0]\n",
    "    print 'Number of errors:', errors\n",
    "    print 'Error Percentage', errors * 100.0 / len(multi_nb_predictions) , '%'\n",
    "\n",
    "    print '====='\n",
    "    print 'Year\\tAmount\\tError %'\n",
    "    for c in class_errors:\n",
    "        print c, '\\t', class_errors[c], '\\t', class_errors[c] * 100.0 / list(classes_test).count(c), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB\n",
      "Number of training examples: 84992\n",
      "Number of test examples: 21249\n",
      "Number of errors: 12629\n",
      "Error Percentage 59.4333851005 %\n",
      "=====\n",
      "Year\tAmount\tError %\n",
      "2008 \t132 \t100.0 %\n",
      "2009 \t362 \t99.7245179063 %\n",
      "2010 \t177 \t100.0 %\n",
      "2011 \t792 \t99.7481108312 %\n",
      "2012 \t1790 \t98.0284775465 %\n",
      "2013 \t3334 \t94.3941109853 %\n",
      "2014 \t3568 \t40.2481669487 %\n",
      "2015 \t2474 \t44.4964028777 %\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "test_classifier(clf, 'MultinomialNB', matrix_train, classes_train, matrix_test, classes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: OvR(LinearSVC)\n"
     ]
    }
   ],
   "source": [
    "#clf = LinearSVC()\n",
    "#test_classifier(clf, 'LinearSVC', matrix_train, classes_train, matrix_test, classes_test)\n",
    "print 'Classifier: OvR(LinearSVC)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "test_classifier(clf, 'KNeighborsClassifier', matrix_train, classes_train, matrix_test, classes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multinomial Bayes OvR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: OvR(MultinomialNB)\n",
      "Number of training examples: 84992\n",
      "Number of test examples: 21249\n",
      "Number of errors: 12869\n",
      "Error Percentage 60.5628500165 %\n",
      "=====\n",
      "Year\tAmount\tError %\n",
      "2008 \t130 \t98.4848484848 %\n",
      "2009 \t361 \t99.4490358127 %\n",
      "2010 \t177 \t100.0 %\n",
      "2011 \t788 \t99.2443324937 %\n",
      "2012 \t1765 \t96.6593647317 %\n",
      "2013 \t3239 \t91.704416761 %\n",
      "2014 \t3919 \t44.2075578116 %\n",
      "2015 \t2490 \t44.7841726619 %\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "test_classifier(clf, 'OvR(MultinomialNB)', matrix_train, classes_train, matrix_test, classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: MultinomialNB\n",
      "Number of training examples: 84992\n",
      "Number of test examples: 21249\n",
      "Number of errors: 12629\n",
      "Error Percentage 59.4333851005 %\n",
      "=====\n",
      "Year\tAmount\tError %\n",
      "2008 \t132 \t100.0 %\n",
      "2009 \t362 \t99.7245179063 %\n",
      "2010 \t177 \t100.0 %\n",
      "2011 \t792 \t99.7481108312 %\n",
      "2012 \t1790 \t98.0284775465 %\n",
      "2013 \t3334 \t94.3941109853 %\n",
      "2014 \t3568 \t40.2481669487 %\n",
      "2015 \t2474 \t44.4964028777 %\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "test_classifier(clf, 'MultinomialNB', matrix_train, classes_train, matrix_test, classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: OvR(MultinomialNB)\n",
      "Number of training examples: 84992\n",
      "Number of test examples: 21249\n",
      "Number of errors: 12869\n",
      "Error Percentage 60.5628500165 %\n",
      "=====\n",
      "Year\tAmount\tError %\n",
      "2008 \t130 \t98.4848484848 %\n",
      "2009 \t361 \t99.4490358127 %\n",
      "2010 \t177 \t100.0 %\n",
      "2011 \t788 \t99.2443324937 %\n",
      "2012 \t1765 \t96.6593647317 %\n",
      "2013 \t3239 \t91.704416761 %\n",
      "2014 \t3919 \t44.2075578116 %\n",
      "2015 \t2490 \t44.7841726619 %\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "test_classifier(clf, 'OvR(MultinomialNB)', matrix_train, classes_train, matrix_test, classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
